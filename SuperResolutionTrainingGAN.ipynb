{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from torch import autograd\n",
    "from fastai.conv_learner import *\n",
    "from fastai.transforms import TfmType\n",
    "from fasterai.transforms import *\n",
    "from fasterai.images import *\n",
    "from fasterai.dataset import *\n",
    "from fasterai.visualize import *\n",
    "from fasterai.callbacks import *\n",
    "from fasterai.loss import *\n",
    "from fasterai.modules import *\n",
    "from fasterai.training import *\n",
    "from fasterai.generators import *\n",
    "from fastai.torch_imports import *\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "import tensorboardX\n",
    "torch.cuda.set_device(3)\n",
    "plt.style.use('dark_background')\n",
    "torch.backends.cudnn.benchmark=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_listy(x): \n",
    "    return isinstance(x, (list,tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hook_inner(m,i,o): \n",
    "    return o\n",
    "    #return o if isinstance(o,Tensor) else o if is_listy(o) else list(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    \"Create a hook on `m` with `hook_func`.\"\n",
    "    def __init__(self, m:nn.Module, hook_func, is_forward:bool=True, detach:bool=True):\n",
    "        self.hook_func,self.detach,self.stored = hook_func,detach,None\n",
    "        f = m.register_forward_hook if is_forward else m.register_backward_hook\n",
    "        self.hook = f(self.hook_fn)\n",
    "        self.removed = False\n",
    "\n",
    "    def hook_fn(self, module:nn.Module, input, output):\n",
    "        \"Applies `hook_func` to `module`, `input`, `output`.\"\n",
    "        if self.detach:\n",
    "            input  = (o.detach() for o in input ) if is_listy(input ) else input.detach()\n",
    "            output = (o.detach() for o in output) if is_listy(output) else output.detach()\n",
    "        self.stored = self.hook_func(module, input, output)\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hook from the model.\"\n",
    "        if not self.removed:\n",
    "            self.hook.remove()\n",
    "            self.removed=True\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__(self, *args): self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hooks():\n",
    "    \"Create several hooks on the modules in `ms` with `hook_func`.\"\n",
    "    def __init__(self, ms, hook_func, is_forward:bool=True, detach:bool=True):\n",
    "        self.hooks = [Hook(m, hook_func, is_forward, detach) for m in ms]\n",
    "\n",
    "    def __getitem__(self,i:int)->Hook: return self.hooks[i]\n",
    "    def __len__(self)->int: return len(self.hooks)\n",
    "    def __iter__(self): return iter(self.hooks)\n",
    "    @property\n",
    "    def stored(self): return [o.stored for o in self]\n",
    "\n",
    "    def remove(self):\n",
    "        \"Remove the hooks from the model.\"\n",
    "        for h in self.hooks: h.remove()\n",
    "\n",
    "    def __enter__(self, *args): return self\n",
    "    def __exit__ (self, *args): self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_grad(m:nn.Module, b:bool=None)->[bool]:\n",
    "    \"If `b` is not set `requires_grad` on all params in `m`, else return `requires_grad` of first param.\"\n",
    "    ps = list(m.parameters())\n",
    "    if not ps: return None\n",
    "    if b is None: return ps[0].requires_grad\n",
    "    for p in ps: p.requires_grad=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loss = F.l1_loss\n",
    "vgg_m = vgg16_bn(True).features.cuda().eval()\n",
    "requires_grad(vgg_m, False)\n",
    "blocks = [i-1 for i,o in enumerate(children(vgg_m)) if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [vgg_m[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    n,c,h,w = x.size()\n",
    "    x = x.view(n, c, -1)\n",
    "    return (x @ x.transpose(1,2))/(c*h*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_outputs(modules, detach:bool=True, grad:bool=False)->Hooks:\n",
    "    \"Return `Hooks` that store activations of all `modules` in `self.stored`\"\n",
    "    return Hooks(modules, _hook_inner, detach=detach, is_forward=not grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewFeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n",
    "              ] + [f'gram_{i}' for i in range(len(layer_ids))]\n",
    "\n",
    "    def make_features(self, x, clone=False):\n",
    "        self.m_feat(x)\n",
    "        return [(o.clone() if clone else o) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [base_loss(input,target)]\n",
    "        self.feat_losses += [base_loss(f_in, f_out)*w\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n",
    "                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        self.metrics = dict(zip(self.metric_names, self.feat_losses))\n",
    "        return sum(self.feat_losses)\n",
    "    \n",
    "    def __del__(self): self.hooks.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MseLoss(nn.Module):\n",
    "    def __init__(self, multiplier:int=1.0):\n",
    "        super().__init__()\n",
    "        self.multiplier=multiplier\n",
    "        self.fn=F.mse_loss\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return self.fn(input,target)*self.multiplier\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feat_loss = NewFeatureLoss(vgg_m, blocks[2:5], [5,15,2])\n",
    "feat_loss = MseLoss(multiplier=10)\n",
    "#feat_loss = FeatureLoss(multiplier=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET = Path('data/imagenet/ILSVRC/Data/CLS-LOC/train')\n",
    "proj_id = 'SuperResResCrit11_mse10'\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "#pretrained in SuperResolutionTrainingPreTrain\n",
    "gpath = Path('superres2x34_gen_pretrain.h5')\n",
    "#pretrained critic path\n",
    "dpath = IMAGENET.parent/('ResCriticPre11_crit_128.h5')\n",
    "#dpath = IMAGENET.parent/('colorize_critic_192.h5')\n",
    "\n",
    "c_lr=2e-4\n",
    "c_lrs = np.array([c_lr,c_lr,c_lr])\n",
    "\n",
    "g_lr=c_lr/5\n",
    "g_lrs = np.array([g_lr/100,g_lr/10,g_lr])\n",
    "\n",
    "scale=2\n",
    "keep_pcts=[0.50,0.50]\n",
    "gen_freeze_tos=[-1,0]\n",
    "lrs_unfreeze_factor=0.05\n",
    "x_tfms = []\n",
    "extra_aug_tfms = [RandomLighting(0.1, 0.1, tfm_y=TfmType.PIXEL)]\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Unet34_V2(nf_factor=2, scale=scale).cuda()\n",
    "#netGVis = ModelVisualizationHook(TENSORBOARD_PATH, netG, 'netG')\n",
    "load_model(netG, gpath)\n",
    "\n",
    "netD = DCCriticDense(ni=3, nf=124).cuda()\n",
    "#netDVis = ModelVisualizationHook(TENSORBOARD_PATH, netD, 'netD')\n",
    "load_model(netD, dpath, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GANTrainer(netD=netD, netG=netG, genloss_fns=[feat_loss] , max_critic_loops=1000)\n",
    "trainerVis = GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=False, visual_iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheds=[]\n",
    "\n",
    "scheds.extend(GANTrainSchedule.generate_schedules(szs=[128,128], bss=[16,16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=keep_pcts, \n",
    "    save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=gen_freeze_tos, reduce_x_scale=scale))\n",
    "\n",
    "#c_lrs=c_lrs/4\n",
    "#g_lrs=g_lrs/4\n",
    "\n",
    "#unshock\n",
    "#scheds.extend(GANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.1], \n",
    "    #save_base_name=proj_id, c_lrs=c_lrs/10, g_lrs=g_lrs/10, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "#scheds.extend(GANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.5], \n",
    "    #save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "#scheds.extend(GANTrainSchedule.generate_schedules(szs=[192], bss=[16], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.5], \n",
    "    #save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n",
    "\n",
    "#c_lrs=c_lrs/4\n",
    "#g_lrs=g_lrs/4\n",
    "\n",
    "#unshock\n",
    "#scheds.extend(GANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.1], \n",
    "    #save_base_name=proj_id, c_lrs=c_lrs/10, g_lrs=g_lrs/10, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "#scheds.extend(GANTrainSchedule.generate_schedules(szs=[256], bss=[8], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.5], \n",
    "    #save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(GANTrainSchedule.generate_schedules(szs=[256], bss=[4], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.5], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[-1], reduce_x_scale=scale))\n",
    "\n",
    "scheds.extend(GANTrainSchedule.generate_schedules(szs=[256], bss=[4], path=IMAGENET, x_tfms=x_tfms, extra_aug_tfms=extra_aug_tfms, keep_pcts=[0.5], \n",
    "    save_base_name=proj_id, c_lrs=c_lrs, g_lrs=g_lrs, lrs_unfreeze_factor=lrs_unfreeze_factor, gen_freeze_tos=[0], reduce_x_scale=scale))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(scheds=scheds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
