{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from torch import autograd\n",
    "from fastai.conv_learner import *\n",
    "from fastai.transforms import TfmType\n",
    "from fasterai.transforms import *\n",
    "from fasterai.images import *\n",
    "from fasterai.dataset import *\n",
    "from fasterai.visualize import *\n",
    "from fasterai.callbacks import *\n",
    "from fasterai.loss import *\n",
    "from fasterai.modules import *\n",
    "from fasterai.training import *\n",
    "from fasterai.generators import *\n",
    "from fastai.torch_imports import *\n",
    "from pathlib import Path\n",
    "from itertools import repeat\n",
    "import tensorboardX\n",
    "torch.cuda.set_device(2)\n",
    "plt.style.use('dark_background')\n",
    "torch.backends.cudnn.benchmark=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET = Path('data/imagenet/ILSVRC/Data/CLS-LOC/train')\n",
    "proj_id = 'superres2x34_pre'\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "gpath = IMAGENET.parent/(proj_id + '_gen_256.h5')\n",
    "\n",
    "lr=5e-4\n",
    "lrs = np.array([lr/100,lr/10,lr])\n",
    "\n",
    "sz=128\n",
    "scale=2\n",
    "keep_pct=0.25\n",
    "bs=64\n",
    "lrs_unfreeze_factor=0.05\n",
    "x_tfms = []\n",
    "extra_aug_tfms = [RandomLighting(0.1, 0.1, tfm_y=TfmType.PIXEL)]\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Unet34_V2(nf_factor=2, scale=scale).cuda()\n",
    "#netGVis = ModelVisualizationHook(TENSORBOARD_PATH, netG, 'netG')\n",
    "#load_model(netG, gpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = ImageGenDataLoader(sz=sz, bs=bs, path=IMAGENET, keep_pct=keep_pct, x_tfms=x_tfms, reduce_x_scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = dataLoader.get_model_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnerGenModuleWrapper():\n",
    "    def __init__(self, model: GeneratorModule, name:str):\n",
    "        self.model = to_gpu(model)\n",
    "        self.name = name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        return self.model.get_layer_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = LearnerGenModuleWrapper(netG, 'unet')\n",
    "learn = ConvLearner(md, unet)\n",
    "imgGenVis = ImageGenVisualizationCallback(TENSORBOARD_PATH, netG, md, 'learner')\n",
    "learn.metrics = []\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = F.mse_loss\n",
    "#learn.crit = FeatureLoss(multiplier=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.lr_find(1e-4, 1e1, wds=wd, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.sched.plot(n_skip=0, n_skip_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, cycle_len=1, wds=wd, use_clr_beta=(10,10,0.95,0.85), callbacks=[imgGenVis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs/10, 1, cycle_len=1, wds=wd, use_clr_beta=(10,10,0.95,0.85), callbacks=[imgGenVis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(netG, 'superres2x34_gen_pretrain.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
